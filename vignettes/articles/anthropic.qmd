---
title: "Anthropic (Claude)"
format: html
execute:
  echo: true
  eval: false
---

# Introduction

This article covers using the Anthropic (Claude) provider with `argent`. Anthropic offers powerful extended thinking capabilities, server-side tools, and prompt caching for cost optimization.

# Setup

```{r claude-init}
anthropic <- Anthropic$new(api_key = Sys.getenv("ANTHROPIC_API_KEY"))
```

```{r}
mirai::daemons(4) # To enable parallel tool calling
```

# Discovering Models

```{r}
anthropic$list_models()
```

# Basic Completion

```{r}
anthropic$chat(
    "What's the R programming language? Answer in three sentences.",
    model = "claude-haiku-4-5-20251001"
)
```

# Tool Calling + Structured Output + Thinking

Anthropic supports extended thinking via the `thinking_budget` parameter, which allows models to reason through problems before responding.

First, define some web-related tools (search, crawl, fetch, and a general-use tool) bundled in a `web_tools` list:

```{=html}
<details>
<summary>Web Tools Implementation</summary>
```

{{< include "_web.qmd" >}}

</details>

Then, let's define a JSON schema for the structured output using `schema()`:

```{r}
package_info_schema <- schema(
    name = "package_info",
    description = "Information about an R package release",
    release_version = "string* The release version of the package",
    release_date = "string* The release date of the `release_version`"
)
```

Then, run the agent:

```{r}
anthropic$chat(
    "When was the first release of the R 'ellmer' package on GitHub?",
    model = "claude-haiku-4-5-20251001",
    thinking_budget = 1024,
    tools = list(as_tool(web_search), as_tool(web_fetch)),
    output_schema = package_info_schema
)
```

```{verbatim}
$release_version
[1] "0.1.0"

$release_date
[1] "2025-01-09"
```

The model will keep calling tools until it has enough information to answer the question.

## Extracting Reasoning

```{r}
cat(anthropic$get_reasoning_text())
```

Alternatively, simply `print(anthropic)` to see the reasoning and answers' text in the console, turn by turn.

::: {.callout-note appearance="simple"}
`get_reasoning_text()` and `get_content_text()` use the last API response (`anthropic$get_last_response()`) by default.
:::

# Server-side Tools

Server-side tools are tools you can call without having to define them yourself. They will be run on the provider's server.

Anthropic provides three server-side tools:

- **web_search** - Web search with citations
- **web_fetch** - Fetch and process URLs
- **code_execution** - Execute commands, write and execute python code, analyze data, create visualizations and files

## Server-side: Web Search

```{r}
anthropic$chat(
    "What's the latest version of the R 'ellmer' package?",
    model = "claude-haiku-4-5-20251001",
    tools = list("web_search"),
    output_schema = package_info_schema
)
```

::: {.callout-tip appearance="simple"}

The `web_search` tool supports additional parameters like `allowed_domains`, `exclude_domains`, `max_uses`, and `user_location`. See [Anthropic's documentation](https://docs.claude.com/en/docs/agents-and-tools/tool-use/web-search-tool#tool-definition) for details.

```{r}
anthropic$chat(
    "What's the latest version of the R 'ellmer' package?",
    model = "claude-haiku-4-5-20251001",
    tools = list(
        list(
            type = "web_search_20250305",
            name = "web_search",
            blocked_domains = list("rdrr.io"),
            max_uses = 2
        )
    ),
    output_schema = package_info_schema
)
```

:::

We can call `anthropic$get_supplementary()` to get the citations.


## Server-side: Web Fetch

This server tool lets the LLM fetch the contents of URLs given to it in the prompt.

```{r}
anthropic$chat(
    "Summarize the main changes in the current development version of the R 'ellmer' package from: https://raw.githubusercontent.com/tidyverse/ellmer/main/NEWS.md",
    model = "claude-haiku-4-5-20251001",
    tools = list("web_fetch")
)
```

The `web_fetch` tool also supports parameters like `allowed_domains`, `exclude_domains`, and `max_uses`. See [Anthropic's documentation](https://docs.claude.com/en/docs/agents-and-tools/tool-use/web-fetch-tool#tool-definition) for details.

We can call `anthropic$get_supplementary()` to get the details of the searches the server made.


## Server-side: Code Execution

Anthropic's code_execution tool provides a sandboxed environment for executing shell commands and file operations.

::: {.callout-note appearance="simple"}

- **Pricing**: $0.05/session-hour with 5-minute minimum
- **Resources**: 5GB RAM/disk, 1 CPU, no internet access
- **Workspace**: Linked to the API key (files can be downloaded)
- **Sub-tools**:
  - `bash_code_execution` - Execute bash commands
  - `text_editor_code_execution` - Edit files
- **Expiration**: 30 days after creation

Claude automatically determines which sub-tool to use.

:::

**Example: Analyzing the Penguins Dataset**

```{r}
penguins_url <- "https://raw.githubusercontent.com/allisonhorst/palmerpenguins/refs/heads/main/inst/extdata/penguins.csv"
penguins_file <- anthropic$upload_file(penguins_url)

code_exec_tool <- list(type = "code_execution", file_ids = list(penguins_file$id))

anthropic$chat(
    "Create a summary table showing average body_mass grouped by species, sex, and year. Save as CSV.",
    model = "claude-sonnet-4-5-20250929",
    tools = list(code_exec_tool)
)
```

Inspect the generated code:

```{r}
cat(anthropic$get_generated_code(langs = c("python"), as_chunks = TRUE))
```

```{=html}
<details>
<summary>Generated Code</summary>
```

```python

import pandas as pd
import os

# Read the CSV file
input_file = os.path.join(os.environ['INPUT_DIR'], 'fileaa34f5b158276.csv')
df = pd.read_csv(input_file)

# Display basic info about the data
print("Original data shape:", df.shape)
print("\nColumn names:", df.columns.tolist())
print("\nFirst few rows:")
print(df.head())

# Check for missing values in key columns
print("\nMissing values in key columns:")
print(f"species: {df['species'].isna().sum()}")
print(f"sex: {df['sex'].isna().sum()}")
print(f"year: {df['year'].isna().sum()}")
print(f"body_mass: {df['body_mass'].isna().sum()}")

# Remove rows where body_mass is NA (can't calculate average for missing values)
# Also remove rows where sex is NA if you want clean grouping
df_clean = df.dropna(subset=['body_mass', 'sex', 'species', 'year'])

print(f"\nData shape after removing rows with missing values: {df_clean.shape}")

# Group by species, sex, and year, and calculate average body_mass
summary = df_clean.groupby(['species', 'sex', 'year'])['body_mass'].mean().reset_index()
summary.columns = ['species', 'sex', 'year', 'average_body_mass']

# Round to 2 decimal places for readability
summary['average_body_mass'] = summary['average_body_mass'].round(2)

# Sort by species, year, and sex for better readability
summary = summary.sort_values(['species', 'year', 'sex']).reset_index(drop=True)

print("\nSummary table:")
print(summary)

# Save to CSV
output_file = '/tmp/body_mass_summary.csv'
summary.to_csv(output_file, index=False)
print(f"\nSummary saved to {output_file}")

# Copy to OUTPUT_DIR for export
output_export = os.path.join(os.environ['OUTPUT_DIR'], 'body_mass_summary.csv')
summary.to_csv(output_export, index=False)
print(f"Summary exported to {output_export}")

```

</details>

Download the generated output file to `/data`:

```{r}
downloaded_path <- anthropic$download_generated_files(dest_path = "data")
#> âœ” [Anthropic] File downloaded to: data/body_mass_summary.csv
```

```{r}
read.csv(downloaded_path)
```

```{verbatim}
     species    sex year average_body_mass
1     Adelie female 2007           3389.77
2     Adelie   male 2007           4038.64
3     Adelie female 2008           3386.00
4     Adelie   male 2008           4098.00
5     Adelie female 2009           3334.62
6     Adelie   male 2009           3995.19
7  Chinstrap female 2007           3569.23
8  Chinstrap   male 2007           3819.23
9  Chinstrap female 2008           3472.22
10 Chinstrap   male 2008           4127.78
11 Chinstrap female 2009           3522.92
12 Chinstrap   male 2009           3927.08
13    Gentoo female 2007           4618.75
14    Gentoo   male 2007           5552.94
15    Gentoo female 2008           4627.27
16    Gentoo   male 2008           5410.87
17    Gentoo female 2009           4786.25
18    Gentoo   male 2009           5510.71
```

Continue asking questions in the same context:

```{r}
penguin_output_schema <- schema(
    name = "penguin_output",
    description = "Schema for the penguin output",
    average_body_mass = "number* The average body_mass",
    species = "string* The species",
    sex = "string* The sex",
    year = "integer* The year"
)

anthropic$chat(
    "What's the average body_mass for the Adelie females in 2009?",
    tools = list("code_execution"),
    output_schema = penguin_output_schema
)
```

```{verbatim}
$species
[1] "Adelie"

$sex
[1] "female"

$year
[1] 2009

$average_body_mass
[1] 3334.62
```

Cleanup:

```{r}
anthropic$delete_file(penguins_file$id)
```


# Multimodal Inputs

Anthropic Claude supports sending:

- PDFs: URLs (as-is, base64, or text content), files (base64, or text content)
- Images: URLs (as-is, or base64), files (base64)
- Remote files (through `as_file_content()`)
- Plain text & code files
- Text-based data files (csv, tsv, json, ..)
- R objects

## Image Comprehension

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Downloading an example image"

bsg04_cast_image_url <- "https://upload.wikimedia.org/wikipedia/en/1/1a/Battlestar_Galactica_%282004%29_cast.jpg"
bsg04_cast_image_path <- download_temp_file(bsg04_cast_image_url)
```

**Sending a local image:**

When providing a path to a local image, it will automatically be converted to base64 before being sent to the server.

```{r}
anthropic$chat(
    "Who are the characters in this image, and what show is it from?",
    bsg04_cast_image_path,
    model = "claude-haiku-4-5-20251001"
)
```

**Sending an image URL:**

::: {.callout-note appearance="simple"}

Image URLs are sent as-is to Anthropic.

We could have used the `as_image_content(bsg04_cast_image_url)` helper to make sure the path/url is converted to base64, and, optionally, to resize the image before sending it.

:::

```{r}
anthropic$chat(
    "Who are the characters in this image, and what show is it from?",
    bsg04_cast_image_url,
    model = "claude-haiku-4-5-20251001"
)
```

```{verbatim}
This is the cast from **Battlestar Galactica** (2004-2009), the science fiction series that rebooted the original 1978 show.

The main characters visible in this promotional image include:

- **Edward James Olmos** as Admiral William Adama
- **Mary McDonnell** as President Laura Roslin
- **Katee Sackhoff** as Kara "Starbuck" Thrace
- **Jamie Bamber** as Lee "Apollo" Adama
- **Tricia Helfer** as Number Six
- **James Callis** as Gaius Baltar
- **Grace Park** as Sharon "Athena" Agathon

The show follows the last surviving battleship and its fleet of civilian ships as they search for the mythical planet Earth while being hunted by robotic Cylons. It became known for its complex characters, political intrigue, and exploration of themes like identity, religion, and survival.
```

*So say we all!*

## PDF Comprehension

```{r}
#| output: false
#| code-fold: true
#| code-summary: "Downloading an example PDF (my CV)"

my_cv_url <- "https://ma-riviere.com/res/cv.pdf"
my_cv_pdf_path <- download_temp_file(my_cv_url)
```

**Sending a local PDF:**

When providing the prompt a path to a local PDF, it will automatically be converted to base64 before being sent to the server.

```{r}
anthropic$chat(
    "What's my favorite programming language?",
    my_cv_pdf_path,
    model = "claude-haiku-4-5-20251001"
)
```

```{verbatim}
Based on your resume, your favorite programming language is **R**.
```

*Damn right!*

**Sending PDF URLs:**

For Anthropic, by default, PDF URLs are sent as-is to the server.

However, we can use the `as_text_content()` helper to have `pdftools::pdf_convert()` parse the PDFs and pass their text contents to the model instead.

```{r}
r6_pdf_url <- "https://cran.r-project.org/web/packages/R6/R6.pdf"
s7_pdf_url <- "https://cran.r-project.org/web/packages/S7/S7.pdf"

multimodal_prompt <- list(
    "Give a short summary of the pros and cons of the two class systems in the following PDFs:",
    as_text_content(r6_pdf_url),
    as_text_content(s7_pdf_url)
)

anthropic$chat(!!!multimodal_prompt, model = "claude-sonnet-4-5-20250929")
```

## Sending files

We can also send files directly to the model.

Thanks to the `as_file_content()` helper, we can pass further options to the provider:

```{r}
cv_metadata <- anthropic$upload_file(my_cv_url)

cv_file_ref <- as_file_content(
    cv_metadata$id,
    .provider_options = list(
        title = "Some stuff I've done", 
        context = "The `argent` R package is not yet mentionned on it but will soon be.", 
        citations = TRUE
    )
)

anthropic$chat(
    "What R packages or tools are mentionned in my 'some stuff I've done' document?",
    cv_file_ref,
    model = "claude-haiku-4-5-20251001"
)

anthropic$delete_file(cv_metadata$id)
```


# Prompt Caching

Anthropic supports prompt caching to reduce costs and latency for repeated context.

Enable caching with the `cache_prompt`, `cache_system`, and `cache_tools` parameters:

```{r}
multimodal_prompt <- list(
    "Give a 3 sentences summary of the advantages of S7 over R6",
    as_text_content(r6_pdf_url),
    as_text_content(s7_pdf_url)
)

anthropic$chat(!!!multimodal_prompt, model = "claude-haiku-4-5-20251001", cache_prompt = TRUE)
```

We can check that the content was indeed cached:

```{r}
purrr::pluck(anthropic$get_last_response(), "usage")
```

```{verbatim}
$input_tokens
[1] 2

$cache_creation_input_tokens
[1] 19770

$cache_read_input_tokens
[1] 0

$cache_creation
$cache_creation$ephemeral_5m_input_tokens
[1] 19770

$cache_creation$ephemeral_1h_input_tokens
[1] 0


$output_tokens
[1] 140

$service_tier
[1] "standard"
```

::: {.callout-note appearance="simple"}
Cached content is stored for 5 minutes and reused across requests, significantly reducing token costs for repeated context.

See [Anthropic's prompt caching documentation](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching) for more details.
:::
